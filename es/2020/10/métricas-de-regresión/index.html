<!doctype html><html lang=es><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=content-language content="es"><meta name=color-scheme content="light dark"><meta name=author content="Jonathan Loscalzo"><meta name=description content="Resumen de métricas de regresión de algoritmos de ML"><meta name=keywords content="resume,blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Métricas de Regresión"><meta name=twitter:description content="Resumen de métricas de regresión de algoritmos de ML"><meta property="og:title" content="Métricas de Regresión"><meta property="og:description" content="Resumen de métricas de regresión de algoritmos de ML"><meta property="og:type" content="article"><meta property="og:url" content="https://jonathanloscalzo.github.io/es/2020/10/m%C3%A9tricas-de-regresi%C3%B3n/"><meta property="article:published_time" content="2020-10-30T11:44:43-03:00"><meta property="article:modified_time" content="2020-10-30T11:44:43-03:00"><meta property="og:site_name" content="Jonathan Loscalzo"><title>Métricas de Regresión · Jonathan Loscalzo</title><link rel=canonical href=https://jonathanloscalzo.github.io/es/2020/10/m%C3%A9tricas-de-regresi%C3%B3n/><link rel=preload href="https://jonathanloscalzo.github.io/fonts/forkawesome-webfont.woff2?v=1.1.7" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://jonathanloscalzo.github.io/css/coder.min.9836c03fe5c87d102278a33e86d0591ef36c89b1e17e8e547ebf84c05cee010e.css integrity="sha256-mDbAP+XIfRAieKM+htBZHvNsibHhfo5Ufr+EwFzuAQ4=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://jonathanloscalzo.github.io/css/coder-dark.min.717236c74e0a5208ef73964a9f44c6b443b689a95b270d8b2a40d0c012460dac.css integrity="sha256-cXI2x04KUgjvc5ZKn0TGtEO2ialbJw2LKkDQwBJGDaw=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://jonathanloscalzo.github.io/images/icons8-laptop-16x16.png sizes=32x32><link rel=icon type=image/png href=https://jonathanloscalzo.github.io/images/icons8-laptop-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://jonathanloscalzo.github.io/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=https://jonathanloscalzo.github.io/images/apple-touch-icon.png><script defer src=https://twemoji.maxcdn.com/v/13.0.2/twemoji.min.js integrity=sha384-wyB/MspSJ/r2bT2kCj44qtsYRYlpzO2oAPhRj5myrWD63dt6qWv4x8AZe7Fl3K3b crossorigin=anonymous></script><meta name=generator content="Hugo 0.75.1"></head><body class="preload-transitions colorscheme-dark" onload=twemoji.parse(document.body);><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://jonathanloscalzo.github.io/es>Jonathan Loscalzo</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://jonathanloscalzo.github.io/es/resume/>Curriculum</a></li><li class=navigation-item><a class=navigation-link href=https://jonathanloscalzo.github.io/es/posts/>Blog</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class=navigation-item><a href=https://jonathanloscalzo.github.io/2020/10/regression-metrics/>English</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://jonathanloscalzo.github.io/es/2020/10/m%C3%A9tricas-de-regresi%C3%B3n/>Métricas de Regresión</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i><time datetime=2020-10-30T11:44:43-03:00>October 30, 2020</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>4 minutos de lectura.</span></div><div class=categories><i class="fa fa-folder" aria-hidden=true></i><a href=https://jonathanloscalzo.github.io/es/categories/machine-learning/>machine-learning</a></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i><a href=https://jonathanloscalzo.github.io/es/tags/metrics/>metrics</a>
<span class=separator>•</span>
<a href=https://jonathanloscalzo.github.io/es/tags/machine-learning/>machine-learning</a>
<span class=separator>•</span>
<a href=https://jonathanloscalzo.github.io/es/tags/regression/>regression</a></div></div></header><div><p>Esté será un resumen de las métricas de regresión más comunes y en que situación usar cada una.</p><p>Métricas:</p><ul><li>Error cuadrático medio - MSE</li><li>Raiz del Error cuadrático medio - RMSE</li><li>Error absoluto medio _ MAE</li><li>R al cuadrado, R cuadrado ajustado (R²)</li></ul><h2 id=mse-mean-squared-error>MSE: Mean Squared Error
<a class=heading-link href=#mse-mean-squared-error><i class="fa fa-link" aria-hidden=true></i></a></h2><p><img src=https://jonathanloscalzo.github.io/images/regression_metrics/mse.png alt=formula></p><p>Es el promedio de la diferencia entre la predicción y el resultado real, al cuadrado.<br>Es una función de pérdida (loss function), así que siempre intentamos minimizarla.<br>Dado que está elevado al cuadrado, siempre va a ser positiva.<br>La medida de este error está al cuadrado de las unidades (si tenemos predicciones en centímetros, tendremos centímetros al cuadrado).<br>Una crítica que se le hace a esta métrica es muy sensible a los outliers, si todas las observaciones tienen el mismo peso.<br>La fórmula es semejante a la varianza.</p><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html>Documentación Sklearn</a></p><h2 id=rmse-root-mean-squared-error>RMSE: Root Mean Squared Error
<a class=heading-link href=#rmse-root-mean-squared-error><i class="fa fa-link" aria-hidden=true></i></a></h2><p><img src=https://jonathanloscalzo.github.io/images/regression_metrics/rmse.gif alt></p><p>Es la misma fórmula que la métrica anterior, solo que es la raíz de la misma.<br>Esto nos permite tener la métrica en las mismas unidades que los datos, útil a la hora de representar la información.<br>La fórmula es semejante a la desviación éstandar.<br>No tenemos manera de saber la dirección del error.</p><p>Relacionando los posibles valores con lo anterior:</p><p>Si MSE es mayor a 1 => MSE &lt;= RMSE:</p><div class=highlight><pre style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>mse = 5
rmse = sqrt(5)
&gt;&gt;&gt; 2.23
</code></pre></div><p>Si MSE es menor a 1 => MSE > RMSE:</p><div class=highlight><pre style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>mse = 0.5
rmse = sqrt(0.5)
&gt;&gt;&gt; 0.70
</code></pre></div><p><a href=https://en.wikipedia.org/wiki/Mean_squared_error>Link Wikipedia</a></p><h2 id=mae-mean-absolute-error>MAE: Mean Absolute Error
<a class=heading-link href=#mae-mean-absolute-error><i class="fa fa-link" aria-hidden=true></i></a></h2><p><img src=https://jonathanloscalzo.github.io/images/regression_metrics/mae.gif alt=formula></p><p>Es el valor absoluto del promedio de los errores.<br>No tenemos manera de saber la dirección del error.
Está en la misma unidad que la data que utilizamos.<br>No es derivable.<br>El error crece linealmente, 10 es peor que 1.
Es semejante a RMSE, pero tiene una diferencia importante (dado que la raíz está afuera cuando calculamos la media):</p><ul><li>para errores chicos se comportan más o menos igual.</li><li>para errores grandes, RMSE le da más peso a los outliers (eso por el cuadrado, es más sensible a outliers). Es decir MAE es más robusto (menos sensible a outliers)</li></ul><p>Ejemplo</p><div class=highlight><pre style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse
from toolz import partial

rmse = partial(mse, squared=False) 

a = pd.Series([1,2,3,4,5])
b = a + 3
print(f&#39;RMSE: {rmse(a,b)}&#39;, f&#39;MAE: {mae(a,b)}&#39;)
&gt;&gt;&gt; RMSE: 3.0 MAE: 3.0

b = a*10
print(f&#39;RMSE: {rmse(a,b)}&#39;, f&#39;MAE: {mae(a,b)}&#39;)
&gt;&gt;&gt; RMSE: 29.8496231131986 MAE: 27.0

# para valores muy grandes se ve la penalización en el error.
b = a*100
print(f&#39;RMSE: {rmse(a,b)}&#39;, f&#39;MAE: {mae(a,b)}&#39;)
&gt;&gt;&gt; RMSE: 328.34585424518457 MAE: 297.0


a = pd.Series([1,2,3,4,5])
b = a*100
b = b.append(a)
a = a.append(a)

# En este caso podemos ver que penaliza mucho los valores muy grandes
# Hay 5 muestras muy malas, y 5 muestras iguales.
print(f&#39;RMSE: {rmse(a,b)}&#39;, f&#39;MAE: {mae(a,b)}&#39;)
&gt;&gt;&gt; RMSE: 232.17558011125976 MAE: 148.5
</code></pre></div><p>Entonces, ¿cuando deberíamos usar una sobre la otra? Depende el objetivo del problema.</p><ol><li>si queremos vender productos y queremos hacer una predicción de &ldquo;cuantos&rdquo;, decir +/- 10 utilizando MAE podría ser correcto, ya que tiene en cuenta el promedio de todos los errores.</li><li>si queremos verificar la temperatura, y nuestro algoritmo debería ser más sensible a valores grandes (mucha temperatura en un instante puede ser un mal síntoma). En este caso preferiríamos usar RMSE.</li></ol><p><a href=https://en.wikipedia.org/wiki/Mean_absolute_error>Link Wikipedia</a></p><h2 id=r-__-coeficiente-de-determinación>R² __ Coeficiente de determinación
<a class=heading-link href=#r-__-coeficiente-de-determinaci%c3%b3n><i class="fa fa-link" aria-hidden=true></i></a></h2><p><img src=https://jonathanloscalzo.github.io/images/regression_metrics/rsquared.png alt=formula></p><p>y_hat es la predicción
y_i es el valor real
luego está dividida por y_i - y_bar, donde y_bar es el promedio de todas las predicciones.</p><p>Lo que expresa es R² es la proporción de que tan bueno es nuestro modelo sobre un modelo más ingenuo (por y_bar)</p><p>R² es una medida que indica cuanta varianza de la variable dependiente es explicada por la variable independiente.</p><p>Puede tener valores negativos, indicando &ldquo;muy malos resultados&rdquo;.<br>No tiene unidades, lo que permite que sea más facil de interpretar entre distintos datasets y modelos.</p><p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score>Documentación Sklearn</a>
<a href=https://www.investopedia.com/terms/r/r-squared.asp>Investopedia</a>
<a href=https://en.wikipedia.org/wiki/Coefficient_of_determination>Wikipedia</a></p><h3 id=keys--refs>Keys & Refs
<a class=heading-link href=#keys--refs><i class="fa fa-link" aria-hidden=true></i></a></h3><blockquote><p>The most important metrics to evaluate a model are root mean squared error (RMSE) and R-squared (R²) - Practical Statistics for Data Scientists</p></blockquote><ul><li><a href=https://thedatascientist.com/performance-measures-rmse-mae/>Perfomance Measures: RMSE vs MAE</a></li><li><a href=https://sitiobigdata.com/2018/08/27/machine-learning-metricas-regresion-mse/>Métricas de Regresión</a></li><li><a href="https://www.youtube.com/watch?v=PjnKeAv5WmE">Youtube - Regression metrics</a></li></ul></div><footer><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"jonathanloscalzo"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></footer></article></section></div><footer class=footer><section class=container>©
2021
Jonathan Loscalzo</section></footer></main><script src=https://jonathanloscalzo.github.io/js/coder.min.f92783b4545b68f3523e5d6ad91d93f76818f9d0db2ffa13bda31b6119cde62b.js integrity="sha256-+SeDtFRbaPNSPl1q2R2T92gY+dDbL/oTvaMbYRnN5is="></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-178412956-1','auto');ga('send','pageview');}</script></body></html>